import midi_io.notes_handling as notes_handling

import tensorflow as tf


def slice_outputs(rnn_outputs, correct_outputs, notes_type):
    """
    Slice output which will be compared for loss for pitch, delta_time and
    duration parts.
    :param rnn_outputs: outputs generated by rnn (2d tensor of shape
                        (batch_size x (roll_out - 1) x note_vector_length)
    :param correct_outputs: shifted by 1 (in frame) network inputs
    :param notes_type: type of outputted notes
                       (whether it is guitar or drums note)
    :return: sliced outputs parts
    """

    # Determine pitch_part_length value.
    if notes_type == notes_handling.GUITAR_NOTE:
        pitch_part_length = notes_handling.GUITAR_PITCH_VECTOR_LENGTH
    else:
        pitch_part_length = notes_handling.DRUMS_PITCH_VECTOR_LENGTH

    # Determine outputs slice points.
    # start -> first_slice_point = pitch part
    # first_slice_point -> second_slice_point = delta time part
    # second_slice_point -> end = duration part
    first_slice_point = pitch_part_length
    second_slice_point = pitch_part_length + notes_handling.TIME_VECTOR_LENGTH

    # Get pitch, delta time and duration parts.
    rnn_outputs_pitch_part = rnn_outputs[:, :first_slice_point]
    correct_outputs_pitch_part = correct_outputs[:, :first_slice_point]
    rnn_outputs_delta_time_part = rnn_outputs[
        :, first_slice_point:second_slice_point
    ]
    correct_outputs_delta_time_part = correct_outputs[
        :, first_slice_point:second_slice_point
    ]
    rnn_outputs_duration_part = rnn_outputs[:, second_slice_point:]
    correct_outputs_duration_part = correct_outputs[:, second_slice_point:]

    return rnn_outputs_pitch_part, correct_outputs_pitch_part, \
           rnn_outputs_delta_time_part, correct_outputs_delta_time_part, \
           rnn_outputs_duration_part, correct_outputs_duration_part


def create_guitar_pitch_loss(
    rnn_guitar_pitch_outputs, correct_guitar_pitch_outputs,
    guitar_pitch_in_octave_loss_multiplier, guitar_octave_loss_multiplier
):
    """
    Create tensorflow node for guitar pitch (pitch in octave and octave) rnn
    outputs. Loss for guitar pitch is calculated by combining 2 classification
    losses to pitch in octave and octave parts of rnn pitch output.
    :param rnn_guitar_pitch_outputs: pitch vectors generated by rnn (2d tensor
                                     of shape (batch_size x (roll_out - 1) x
                                     guitar_pitch_vector_length)
    :param correct_guitar_pitch_outputs: shifted by 1 pitch inputs (same shape
                                         as rnn outputs)
    :param guitar_pitch_loss_multiplier: multiplier applied to pitch in octave
                                         loss part
    :param guitar_octave_loss_multiplier: multiplier applied to octave loss
                                          part
    :return: created guitar pitch loss node
    """

    # Slice rnn outputs and correct values compared with them for pitch in
    # octave and octave parts.
    rnn_guitar_pitch_in_octave_outputs = rnn_guitar_pitch_outputs[
        :, :notes_handling.PITCHES_PER_OCTAVE + 1
    ]
    rnn_guitar_octave_outputs = rnn_guitar_pitch_outputs[
        :, notes_handling.PITCHES_PER_OCTAVE + 1:
    ]
    correct_guitar_pitch_in_octave_outputs = correct_guitar_pitch_outputs[
        :, :notes_handling.PITCHES_PER_OCTAVE + 1
    ]
    correct_guitar_octave_outputs = correct_guitar_pitch_outputs[
        :, notes_handling.PITCHES_PER_OCTAVE + 1:
    ]

    # Calculate pitch in octave and octave softmax losses.
    guitar_pitch_in_octave_softmax_loss = \
        tf.nn.softmax_cross_entropy_with_logits(
            labels=correct_guitar_pitch_in_octave_outputs,
            logits=rnn_guitar_pitch_in_octave_outputs
        )
    guitar_octave_softmax_loss = tf.nn.softmax_cross_entropy_with_logits(
        labels=correct_guitar_octave_outputs, logits=rnn_guitar_octave_outputs
    )

    # Calculate average losses and sum them for total pitch loss.
    guitar_pitch_in_octave_loss = tf.reduce_mean(
        guitar_pitch_in_octave_softmax_loss
    )
    guitar_octave_loss = tf.reduce_mean(guitar_octave_softmax_loss)
    guitar_pitch_loss = guitar_pitch_in_octave_loss_multiplier * \
                        guitar_pitch_in_octave_loss + \
                        guitar_octave_loss_multiplier * guitar_octave_loss

    return guitar_pitch_loss


def create_drums_pitch_loss(
    rnn_drums_pitch_outputs, correct_drums_pitch_outputs,
    drums_pitch_loss_multiplier
):
    """
    Create tensorflow node for drums pitch loss. This loss is simple
    classification loss on whole rnn pitch outputs.
    :param rnn_drums_pitch_outputs: pitch vectors generated by rnn (2d tensor
                                     of shape (batch_size x (roll_out - 1) x
                                     drums_pitch_vector_length)
    :param correct_drums_pitch_outputs: shifted by 1 pitch inputs (same shape
                                         as rnn outputs)
    :return: created drums pitch loss node
    """

    # No slicing required here.
    # Calculate pitch classification softmax loss.
    drums_pitch_softmax_loss = tf.nn.softmax_cross_entropy_with_logits(
        labels=correct_drums_pitch_outputs,
        logits=rnn_drums_pitch_outputs
    )

    drums_pitch_loss = drums_pitch_loss_multiplier * \
                       tf.reduce_mean(drums_pitch_softmax_loss)
    return drums_pitch_loss


def create_time_loss_node(
    rnn_time_outputs, correct_time_outputs,
    time_length_loss_multiplier, time_type_loss_multiplier
):
    """
    Create tensorflow node for time (delta time/duration) loss calculation.
    Loss for time is calculated by applying 2 softmax cross entropy losses
    for time interval length (1/64, 1/32 ... of note) and for time interval
    type (normal, triplet or dotted).
    :param rnn_time_outputs: time vectors generated by rnn (2d tensor of shape
                             (batch_size x (roll_out - 1) x time_vector_length)
    :param correct_time_outputs: shifted by 1 time inputs provided to rnn
                                 (the same shape as rnn_time_outputs)
    :param time_length_loss_multiplier: multiplier of length loss part
    :param time_type_loss_multiplier: multiplier of type loss part
    :return: created loss node
    """

    # Slice analyzed outputs for time length and time type parts.
    rnn_time_length_outputs = rnn_time_outputs[
        :, :notes_handling.TIME_LENGTH_VECTOR_LENGTH
    ]
    rnn_time_type_outputs = rnn_time_outputs[
        :, notes_handling.TIME_LENGTH_VECTOR_LENGTH:
    ]
    correct_time_length_outputs = correct_time_outputs[
        :, :notes_handling.TIME_LENGTH_VECTOR_LENGTH
    ]
    correct_time_type_outputs = correct_time_outputs[
        :, notes_handling.TIME_LENGTH_VECTOR_LENGTH:
    ]

    # Calculate softmax cross entropy classification loss for each part
    # separately.
    time_length_softmax_loss = tf.nn.softmax_cross_entropy_with_logits(
        labels=correct_time_length_outputs, logits=rnn_time_length_outputs
    )
    time_type_softmax_loss = tf.nn.softmax_cross_entropy_with_logits(
        labels=correct_time_type_outputs, logits=rnn_time_type_outputs
    )

    # Calculate average losses across whole batch and sum them with multipliers
    # to create complete time loss.
    time_length_loss = tf.reduce_mean(time_length_softmax_loss)
    time_type_loss = tf.reduce_mean(time_type_softmax_loss)
    time_loss = time_length_loss_multiplier * time_length_loss + \
                time_type_loss_multiplier * time_type_loss

    return time_loss
